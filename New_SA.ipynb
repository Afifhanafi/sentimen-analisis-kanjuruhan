{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b7fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class PreprocessingText:\n",
    "    def _init_(self):\n",
    "        self.slang_list = [kamus.strip('\\n').strip('\\r') for kamus in open('/slang.txt')]\n",
    "        self.stopword_list = [line.strip('\\n')for line in open('/stop.txt')]\n",
    "        \n",
    "    # Case Folding\n",
    "    def CaseFolding(self, tweets):\n",
    "        tweets = tweets.lower()\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Cleansing\n",
    "    def Cleansing(self, tweets):\n",
    "        # Menghilangkan mention, hashtag, character reference\n",
    "        tweets = re.sub('[@#&][A-Za-z0-9_]+',\" \", tweets)\n",
    "\n",
    "        # Menghilangkan Tautan\n",
    "        tweets = re.sub(\"\\w+:\\/\\/\\S+\",\" \", tweets)\n",
    "\n",
    "        # Menghilangkan tanda baca\n",
    "        tweets = re.sub('[()!?;,]', ' ', tweets)\n",
    "        tweets = re.sub('\\[.*?\\]',' ', tweets)\n",
    "\n",
    "        # Menghilangkan tanda selain huruf\n",
    "        tweets = re.sub(\"[^a-z]\",\" \", tweets)\n",
    "\n",
    "        # Menghilangkan spasi lebih dari 1\n",
    "        tweets = ' '.join(tweets.split())\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Replace Slangwords\n",
    "    def Slangwords(self, tweets):\n",
    "        for line in self.slang_list:\n",
    "            slangword = line.strip().split(\":\")\n",
    "            if slangword[0] in tweets.split(\" \"):\n",
    "                tweets = tweets.replace(slangword[0] + \" \", slangword[1] + \" \")\n",
    "                tweets = tweets.replace(\" \" + slangword[0], \" \" + slangword[1])\n",
    "                \n",
    "        return tweets\n",
    "    \n",
    "    # Stopwords Removal\n",
    "    def StopwordsRemoval(self, tweets):\n",
    "        stopwords_list = list(map(lambda x:x.strip(),list(self.stopword_list)))\n",
    "        tweets = tweets.split()\n",
    "        tweets = [w for w in tweets if not w in stopwords_list]\n",
    "        tweets = \" \".join(word for word in tweets)\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Tokenization\n",
    "    def Tokenization(self, tweets):\n",
    "        tweets = tweets.split()\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Normalization (Stemming)\n",
    "    def Stemming(self, tweets):\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "        do = []\n",
    "        for w in tweets:\n",
    "            dt = stemmer.stem(w)\n",
    "            do.append(dt)\n",
    "        d_clean = []\n",
    "        d_clean = \" \".join(do)\n",
    "        print(d_clean)\n",
    "        \n",
    "        return d_clean\n",
    "    \n",
    "    def Stemming1(self, tweets):\n",
    "        stemmer = StemmerFactory.create_stemmer()\n",
    "        tweets = stemmer.stem(tweets)\n",
    "        print(tweets)\n",
    "\n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ddce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>2022-08-31 06:58:15 SE Asia Standard Time</td>\n",
       "      <td>1,43E+18</td>\n",
       "      <td>pinem3paska</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@Indostransfer Harapan saya  Agar Di Sumatera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>2022-08-31 06:54:57 SE Asia Standard Time</td>\n",
       "      <td>968410669</td>\n",
       "      <td>bhaniie_bsf</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@ocehangaluh Haha gimana mau degradasi orang d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>2022-08-31 06:53:15 SE Asia Standard Time</td>\n",
       "      <td>116308596</td>\n",
       "      <td>awaveiro</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>Detail banget woy, sampe pager betis lompat aj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>2022-08-31 06:48:16 SE Asia Standard Time</td>\n",
       "      <td>1,45E+18</td>\n",
       "      <td>loyalisgaruda</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>1,56E+18</td>\n",
       "      <td>2022-08-31 06:45:57 SE Asia Standard Time</td>\n",
       "      <td>124392857</td>\n",
       "      <td>rahmaddiant0</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@PSSI Bukan sobat ambyar?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
       "      <td>1,12E+18</td>\n",
       "      <td>fachsetiawan</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>@lisadepe Ga salah dong gw ngidolain Ajax keti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
       "      <td>7,08E+17</td>\n",
       "      <td>dulqowi</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>@fedriza @PSSI Idem bro, sementara ini dulu aj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>2022-01-01 06:02:04 SE Asia Standard Time</td>\n",
       "      <td>1,28E+18</td>\n",
       "      <td>ganesha010180</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@SiaranBolaLive Ga habis pikir, PSSI menggunak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>2022-01-01 05:59:26 SE Asia Standard Time</td>\n",
       "      <td>1,33E+18</td>\n",
       "      <td>indones30065690</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@tirta_cipeng @PSSI Perusak Sepakbola Sejati I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>1,48E+18</td>\n",
       "      <td>2022-01-01 05:59:02 SE Asia Standard Time</td>\n",
       "      <td>1,28E+18</td>\n",
       "      <td>ganesha010180</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@SiaranBolaLive Problematik. Banyaknya sumber ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id conversation_id                                 created_at  \\\n",
       "0    1,56E+18        1,56E+18  2022-08-31 06:58:15 SE Asia Standard Time   \n",
       "1    1,56E+18        1,56E+18  2022-08-31 06:54:57 SE Asia Standard Time   \n",
       "2    1,56E+18        1,56E+18  2022-08-31 06:53:15 SE Asia Standard Time   \n",
       "3    1,56E+18        1,56E+18  2022-08-31 06:48:16 SE Asia Standard Time   \n",
       "4    1,56E+18        1,56E+18  2022-08-31 06:45:57 SE Asia Standard Time   \n",
       "..        ...             ...                                        ...   \n",
       "539  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
       "540  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
       "541  1,48E+18        1,48E+18  2022-01-01 06:02:04 SE Asia Standard Time   \n",
       "542  1,48E+18        1,48E+18  2022-01-01 05:59:26 SE Asia Standard Time   \n",
       "543  1,48E+18        1,48E+18  2022-01-01 05:59:02 SE Asia Standard Time   \n",
       "\n",
       "       user_id         username    label  \\\n",
       "0     1,43E+18      pinem3paska  NEGATIF   \n",
       "1    968410669      bhaniie_bsf  NEGATIF   \n",
       "2    116308596         awaveiro  NEGATIF   \n",
       "3     1,45E+18    loyalisgaruda  NEGATIF   \n",
       "4    124392857     rahmaddiant0  NEGATIF   \n",
       "..         ...              ...      ...   \n",
       "539   1,12E+18     fachsetiawan  POSITIF   \n",
       "540   7,08E+17          dulqowi  POSITIF   \n",
       "541   1,28E+18    ganesha010180  NEGATIF   \n",
       "542   1,33E+18  indones30065690  NEGATIF   \n",
       "543   1,28E+18    ganesha010180  NEGATIF   \n",
       "\n",
       "                                                 tweet  \n",
       "0    @Indostransfer Harapan saya  Agar Di Sumatera ...  \n",
       "1    @ocehangaluh Haha gimana mau degradasi orang d...  \n",
       "2    Detail banget woy, sampe pager betis lompat aj...  \n",
       "3    @abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...  \n",
       "4                            @PSSI Bukan sobat ambyar?  \n",
       "..                                                 ...  \n",
       "539  @lisadepe Ga salah dong gw ngidolain Ajax keti...  \n",
       "540  @fedriza @PSSI Idem bro, sementara ini dulu aj...  \n",
       "541  @SiaranBolaLive Ga habis pikir, PSSI menggunak...  \n",
       "542  @tirta_cipeng @PSSI Perusak Sepakbola Sejati I...  \n",
       "543  @SiaranBolaLive Problematik. Banyaknya sumber ...  \n",
       "\n",
       "[544 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdc9047",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PreprocessingText' object has no attribute 'slang_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:13\u001b[0m\n",
      "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn [9], line 38\u001b[0m, in \u001b[0;36mPreprocessingText.Slangwords\u001b[1;34m(self, tweets)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSlangwords\u001b[39m(\u001b[39mself\u001b[39m, tweets):\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslang_list:\n\u001b[0;32m     39\u001b[0m         slangword \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m         \u001b[39mif\u001b[39;00m slangword[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m tweets\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PreprocessingText' object has no attribute 'slang_list'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pretext = PreprocessingText()\n",
    "\n",
    "# ======================================================================================================================\n",
    "\n",
    "df_casefolding = df.copy()\n",
    "df_casefolding['tweet'] = df_casefolding['tweet'].apply(pretext.CaseFolding)\n",
    "\n",
    "df_cleansing = df_casefolding.copy()\n",
    "df_cleansing['tweet'] = df_cleansing['tweet'].apply(pretext.Cleansing)\n",
    "# df_cleansing = df_cleansing.drop_duplicates(subset='tweet')\n",
    "\n",
    "df_slangwords = df_cleansing.copy()\n",
    "df_slangwords['tweet'] = df_slangwords['tweet'].apply(pretext.Slangwords)\n",
    "\n",
    "df_stopwords = df_slangwords.copy()\n",
    "df_stopwords['tweet'] = df_stopwords['tweet'].apply(pretext.StopwordsRemoval)\n",
    "\n",
    "df_token = df_stopwords.copy()\n",
    "df_token['tweet'] = df_token['tweet'].apply(pretext.Tokenization)\n",
    "\n",
    "df_stemming = df_token.copy()\n",
    "# df_stemming['tweet'] = df_stemming['tweet'].apply(pretext.Stemming)\n",
    "\n",
    "dataAll = {'Raw Data': df, 'Case Folding': df_casefolding, 'Cleansing': df_cleansing, \n",
    "           'Normalization': df_slangwords, 'StopWords Removal': df_stopwords, 'Stemming': df_stemming,\n",
    "           'Tokenization': df_token}\n",
    "\n",
    "writer = pd.ExcelWriter('./kanjuruhan_sesudah_Preprocessed.xlsx', engine='xlsxwriter', mode='w')\n",
    "\n",
    "for data_sheet in dataAll.keys():\n",
    "    dataAll[data_sheet].to_excel(writer, sheet_name=data_sheet, index=False)\n",
    "\n",
    "writer.close()\n",
    "writer.handles = None\n",
    "\n",
    "print(\"\\n\\n\\nData Preprocessed Saved!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6bb865b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-16 05:18:19 SE Asia Standard Time</td>\n",
       "      <td>1,49E+18</td>\n",
       "      <td>alhusaini_asror</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@mohmahfudmd Benar dan Betul.Ketua PSSI,mundur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-16 05:13:51 SE Asia Standard Time</td>\n",
       "      <td>1442933096</td>\n",
       "      <td>metmalamminggu</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@iIhamzada Dilarang intervensi gara\" aturan fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-16 05:06:34 SE Asia Standard Time</td>\n",
       "      <td>7,88E+17</td>\n",
       "      <td>onedayasmine</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@gibran_tweet Mas.. jadi ketua PSSI yaaa Kalau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-16 05:03:44 SE Asia Standard Time</td>\n",
       "      <td>4812772283</td>\n",
       "      <td>harryunited05</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@medioclubID @PSSI mana orangnya itu2 aja lagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-16 05:00:24 SE Asia Standard Time</td>\n",
       "      <td>1,31E+18</td>\n",
       "      <td>ariflabmed</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>@medioclubID @PSSI Yunus Nusi akan dikenang se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-07 11:47:59 SE Asia Standard Time</td>\n",
       "      <td>521254614</td>\n",
       "      <td>bodoamath</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>lho kapolda sama ketua pssi nya mana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-07 11:47:24 SE Asia Standard Time</td>\n",
       "      <td>1,57E+18</td>\n",
       "      <td>crypto34209511</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@PSSI HAK DAN KEWAJIBAN PENONTON HARUS DI INGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-07 11:43:10 SE Asia Standard Time</td>\n",
       "      <td>2156012929</td>\n",
       "      <td>gbrand_9127</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@CNNIndonesia PSSI juga gk standar FIFA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-07 11:41:33 SE Asia Standard Time</td>\n",
       "      <td>480858414</td>\n",
       "      <td>grrraargh</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>@ainurohman Dia pikir PSSI cuma urus timnas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>1,58E+18</td>\n",
       "      <td>2022-10-07 11:40:32 SE Asia Standard Time</td>\n",
       "      <td>1056988237</td>\n",
       "      <td>davasca_</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>@Gust_Neg @Gusnaabi1 @gumpnhell ((Enak aje mun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id conversation_id                                 created_at  \\\n",
       "0     1,58E+18        1,58E+18  2022-10-16 05:18:19 SE Asia Standard Time   \n",
       "1     1,58E+18        1,58E+18  2022-10-16 05:13:51 SE Asia Standard Time   \n",
       "2     1,58E+18        1,58E+18  2022-10-16 05:06:34 SE Asia Standard Time   \n",
       "3     1,58E+18        1,58E+18  2022-10-16 05:03:44 SE Asia Standard Time   \n",
       "4     1,58E+18        1,58E+18  2022-10-16 05:00:24 SE Asia Standard Time   \n",
       "...        ...             ...                                        ...   \n",
       "1273  1,58E+18        1,58E+18  2022-10-07 11:47:59 SE Asia Standard Time   \n",
       "1274  1,58E+18        1,58E+18  2022-10-07 11:47:24 SE Asia Standard Time   \n",
       "1275  1,58E+18        1,58E+18  2022-10-07 11:43:10 SE Asia Standard Time   \n",
       "1276  1,58E+18        1,58E+18  2022-10-07 11:41:33 SE Asia Standard Time   \n",
       "1277  1,58E+18        1,58E+18  2022-10-07 11:40:32 SE Asia Standard Time   \n",
       "\n",
       "         user_id         username    label  \\\n",
       "0       1,49E+18  alhusaini_asror  NEGATIF   \n",
       "1     1442933096   metmalamminggu  NEGATIF   \n",
       "2       7,88E+17     onedayasmine  NEGATIF   \n",
       "3     4812772283    harryunited05  NEGATIF   \n",
       "4       1,31E+18       ariflabmed  POSITIF   \n",
       "...          ...              ...      ...   \n",
       "1273   521254614        bodoamath  NEGATIF   \n",
       "1274    1,57E+18   crypto34209511  NEGATIF   \n",
       "1275  2156012929      gbrand_9127  NEGATIF   \n",
       "1276   480858414        grrraargh  NEGATIF   \n",
       "1277  1056988237         davasca_  POSITIF   \n",
       "\n",
       "                                                  tweet  \n",
       "0     @mohmahfudmd Benar dan Betul.Ketua PSSI,mundur...  \n",
       "1     @iIhamzada Dilarang intervensi gara\" aturan fi...  \n",
       "2     @gibran_tweet Mas.. jadi ketua PSSI yaaa Kalau...  \n",
       "3     @medioclubID @PSSI mana orangnya itu2 aja lagi...  \n",
       "4     @medioclubID @PSSI Yunus Nusi akan dikenang se...  \n",
       "...                                                 ...  \n",
       "1273              lho kapolda sama ketua pssi nya mana?  \n",
       "1274  @PSSI HAK DAN KEWAJIBAN PENONTON HARUS DI INGA...  \n",
       "1275           @CNNIndonesia PSSI juga gk standar FIFA.  \n",
       "1276        @ainurohman Dia pikir PSSI cuma urus timnas  \n",
       "1277  @Gust_Neg @Gusnaabi1 @gumpnhell ((Enak aje mun...  \n",
       "\n",
       "[1278 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "# data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92af24e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Sentimen Analisis\n",
      "POSITIF :  639 (50.0%)\n",
      "NEGATIF :  639 (50.0%)\n",
      "TOTAL :  1278\n"
     ]
    }
   ],
   "source": [
    "tweets_positive = [t for t in data[\"label\"] if t == \"POSITIF\"]\n",
    "tweets_negative = [t for t in data[\"label\"] if t == \"NEGATIF\"]\n",
    "\n",
    "print(\"Hasil Sentimen Analisis\")\n",
    "print(\"POSITIF : \", len(tweets_positive), \"({}%)\".format(100*len(tweets_positive)/len(data)))\n",
    "print(\"NEGATIF : \", len(tweets_negative), \"({}%)\".format(100*len(tweets_negative)/len(data)))\n",
    "print(\"TOTAL : \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e568e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7b233f4b7a616658a1a466fdf5aa47a8e96adab13ae8534af036626bf05cb68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
