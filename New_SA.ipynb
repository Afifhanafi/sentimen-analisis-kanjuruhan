{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07b7fd4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "class PreprocessingText:\n",
        "    def _init_(self):\n",
        "        self.slang_list = [kamus.strip('\\n').strip('\\r') for kamus in open('/slang.txt')]\n",
        "        self.stopword_list = [line.strip('\\n')for line in open('/stop.txt')]\n",
        "        \n",
        "    # Case Folding\n",
        "    def CaseFolding(self, tweets):\n",
        "        tweets = tweets.lower()\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Cleansing\n",
        "    def Cleansing(self, tweets):\n",
        "        # Menghilangkan mention, hashtag, character reference\n",
        "        tweets = re.sub('[@#&][A-Za-z0-9_]+',\" \", tweets)\n",
        "\n",
        "        # Menghilangkan Tautan\n",
        "        tweets = re.sub(\"\\w+:\\/\\/\\S+\",\" \", tweets)\n",
        "\n",
        "        # Menghilangkan tanda baca\n",
        "        tweets = re.sub('[()!?;,]', ' ', tweets)\n",
        "        tweets = re.sub('\\[.*?\\]',' ', tweets)\n",
        "\n",
        "        # Menghilangkan tanda selain huruf\n",
        "        tweets = re.sub(\"[^a-z]\",\" \", tweets)\n",
        "\n",
        "        # Menghilangkan spasi lebih dari 1\n",
        "        tweets = ' '.join(tweets.split())\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Replace Slangwords\n",
        "    def Slangwords(self, tweets):\n",
        "        for line in self.slang_list:\n",
        "            slangword = line.strip().split(\":\")\n",
        "            if slangword[0] in tweets.split(\" \"):\n",
        "                tweets = tweets.replace(slangword[0] + \" \", slangword[1] + \" \")\n",
        "                tweets = tweets.replace(\" \" + slangword[0], \" \" + slangword[1])\n",
        "                \n",
        "        return tweets\n",
        "    \n",
        "    # Stopwords Removal\n",
        "    def StopwordsRemoval(self, tweets):\n",
        "        stopwords_list = list(map(lambda x:x.strip(),list(self.stopword_list)))\n",
        "        tweets = tweets.split()\n",
        "        tweets = [w for w in tweets if not w in stopwords_list]\n",
        "        tweets = \" \".join(word for word in tweets)\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Tokenization\n",
        "    def Tokenization(self, tweets):\n",
        "        tweets = tweets.split()\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Normalization (Stemming)\n",
        "    def Stemming(self, tweets):\n",
        "        factory = StemmerFactory()\n",
        "        stemmer = factory.create_stemmer()\n",
        "        do = []\n",
        "        for w in tweets:\n",
        "            dt = stemmer.stem(w)\n",
        "            do.append(dt)\n",
        "        d_clean = []\n",
        "        d_clean = \" \".join(do)\n",
        "        print(d_clean)\n",
        "        \n",
        "        return d_clean\n",
        "    \n",
        "    def Stemming1(self, tweets):\n",
        "        stemmer = StemmerFactory.create_stemmer()\n",
        "        tweets = stemmer.stem(tweets)\n",
        "        print(tweets)\n",
        "\n",
        "        return tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ddce0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdc9047",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "pretext = PreprocessingText()\n",
        "\n",
        "# ======================================================================================================================\n",
        "\n",
        "df_casefolding = df.copy()\n",
        "df_casefolding['tweet'] = df_casefolding['tweet'].apply(pretext.CaseFolding)\n",
        "\n",
        "df_cleansing = df_casefolding.copy()\n",
        "df_cleansing['tweet'] = df_cleansing['tweet'].apply(pretext.Cleansing)\n",
        "# df_cleansing = df_cleansing.drop_duplicates(subset='tweet')\n",
        "\n",
        "df_slangwords = df_cleansing.copy()\n",
        "df_slangwords['tweet'] = df_slangwords['tweet'].apply(pretext.Slangwords)\n",
        "\n",
        "df_stopwords = df_slangwords.copy()\n",
        "df_stopwords['tweet'] = df_stopwords['tweet'].apply(pretext.StopwordsRemoval)\n",
        "\n",
        "df_token = df_stopwords.copy()\n",
        "df_token['tweet'] = df_token['tweet'].apply(pretext.Tokenization)\n",
        "\n",
        "df_stemming = df_token.copy()\n",
        "# df_stemming['tweet'] = df_stemming['tweet'].apply(pretext.Stemming)\n",
        "\n",
        "dataAll = {'Raw Data': df, 'Case Folding': df_casefolding, 'Cleansing': df_cleansing, \n",
        "           'Normalization': df_slangwords, 'StopWords Removal': df_stopwords, 'Stemming': df_stemming,\n",
        "           'Tokenization': df_token}\n",
        "\n",
        "writer = pd.ExcelWriter('./kanjuruhan_sesudah_Preprocessed.xlsx', engine='xlsxwriter', mode='w')\n",
        "\n",
        "for data_sheet in dataAll.keys():\n",
        "    dataAll[data_sheet].to_excel(writer, sheet_name=data_sheet, index=False)\n",
        "\n",
        "writer.close()\n",
        "writer.handles = None\n",
        "\n",
        "print(\"\\n\\n\\nData Preprocessed Saved!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bb865b5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:58:15 SE Asia Standard Time</td>\n",
              "      <td>1,43E+18</td>\n",
              "      <td>pinem3paska</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@Indostransfer Harapan saya  Agar Di Sumatera ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:54:57 SE Asia Standard Time</td>\n",
              "      <td>968410669</td>\n",
              "      <td>bhaniie_bsf</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@ocehangaluh Haha gimana mau degradasi orang d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:53:15 SE Asia Standard Time</td>\n",
              "      <td>116308596</td>\n",
              "      <td>awaveiro</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>Detail banget woy, sampe pager betis lompat aj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:48:16 SE Asia Standard Time</td>\n",
              "      <td>1,45E+18</td>\n",
              "      <td>loyalisgaruda</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:44:19 SE Asia Standard Time</td>\n",
              "      <td>1,27E+18</td>\n",
              "      <td>omah_balbalan</td>\n",
              "      <td>Positif</td>\n",
              "      <td>Kenapa sore?   PSSI dan LIB harus tahu ini.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
              "      <td>1,12E+18</td>\n",
              "      <td>fachsetiawan</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@lisadepe Ga salah dong gw ngidolain Ajax keti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
              "      <td>7,08E+17</td>\n",
              "      <td>dulqowi</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@fedriza @PSSI Idem bro, sementara ini dulu aj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:04 SE Asia Standard Time</td>\n",
              "      <td>1,28E+18</td>\n",
              "      <td>ganesha010180</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@SiaranBolaLive Ga habis pikir, PSSI menggunak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 05:59:26 SE Asia Standard Time</td>\n",
              "      <td>1,33E+18</td>\n",
              "      <td>indones30065690</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@tirta_cipeng @PSSI Perusak Sepakbola Sejati I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 05:59:02 SE Asia Standard Time</td>\n",
              "      <td>1,28E+18</td>\n",
              "      <td>ganesha010180</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@SiaranBolaLive Problematik. Banyaknya sumber ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id conversation_id                                 created_at  \\\n",
              "0    1,56E+18        1,56E+18  2022-08-31 06:58:15 SE Asia Standard Time   \n",
              "1    1,56E+18        1,56E+18  2022-08-31 06:54:57 SE Asia Standard Time   \n",
              "2    1,56E+18        1,56E+18  2022-08-31 06:53:15 SE Asia Standard Time   \n",
              "3    1,56E+18        1,56E+18  2022-08-31 06:48:16 SE Asia Standard Time   \n",
              "4    1,56E+18        1,56E+18  2022-08-31 06:44:19 SE Asia Standard Time   \n",
              "..        ...             ...                                        ...   \n",
              "451  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
              "452  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
              "453  1,48E+18        1,48E+18  2022-01-01 06:02:04 SE Asia Standard Time   \n",
              "454  1,48E+18        1,48E+18  2022-01-01 05:59:26 SE Asia Standard Time   \n",
              "455  1,48E+18        1,48E+18  2022-01-01 05:59:02 SE Asia Standard Time   \n",
              "\n",
              "       user_id         username    label  \\\n",
              "0     1,43E+18      pinem3paska  Negatif   \n",
              "1    968410669      bhaniie_bsf  Negatif   \n",
              "2    116308596         awaveiro  Negatif   \n",
              "3     1,45E+18    loyalisgaruda  Negatif   \n",
              "4     1,27E+18    omah_balbalan  Positif   \n",
              "..         ...              ...      ...   \n",
              "451   1,12E+18     fachsetiawan  Positif   \n",
              "452   7,08E+17          dulqowi  Positif   \n",
              "453   1,28E+18    ganesha010180  Negatif   \n",
              "454   1,33E+18  indones30065690  Negatif   \n",
              "455   1,28E+18    ganesha010180  Negatif   \n",
              "\n",
              "                                                 tweet  \n",
              "0    @Indostransfer Harapan saya  Agar Di Sumatera ...  \n",
              "1    @ocehangaluh Haha gimana mau degradasi orang d...  \n",
              "2    Detail banget woy, sampe pager betis lompat aj...  \n",
              "3    @abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...  \n",
              "4          Kenapa sore?   PSSI dan LIB harus tahu ini.  \n",
              "..                                                 ...  \n",
              "451  @lisadepe Ga salah dong gw ngidolain Ajax keti...  \n",
              "452  @fedriza @PSSI Idem bro, sementara ini dulu aj...  \n",
              "453  @SiaranBolaLive Ga habis pikir, PSSI menggunak...  \n",
              "454  @tirta_cipeng @PSSI Perusak Sepakbola Sejati I...  \n",
              "455  @SiaranBolaLive Problematik. Banyaknya sumber ...  \n",
              "\n",
              "[456 rows x 7 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "# data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "92af24e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil Sentimen Analisis\n",
            "Positif :  228 (50.0%)\n",
            "Negatif :  228 (50.0%)\n",
            "TOTAL :  456\n"
          ]
        }
      ],
      "source": [
        "tweets_positive = [t for t in data[\"label\"] if t == \"Positif\"]\n",
        "tweets_negative = [t for t in data[\"label\"] if t == \"Negatif\"]\n",
        "\n",
        "print(\"Hasil Sentimen Analisis\")\n",
        "print(\"Positif : \", len(tweets_positive), \"({}%)\".format(100*len(tweets_positive)/len(data)))\n",
        "print(\"Negatif : \", len(tweets_negative), \"({}%)\".format(100*len(tweets_negative)/len(data)))\n",
        "print(\"TOTAL : \", len(data))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a7b233f4b7a616658a1a466fdf5aa47a8e96adab13ae8534af036626bf05cb68"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
