{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class PreprocessingText:\n",
    "    def _init_(self):\n",
    "        self.slang_list = [kamus.strip('\\n').strip('\\r') for kamus in open('/slang.txt')]\n",
    "        self.stopword_list = [line.strip('\\n')for line in open('/stop.txt')]\n",
    "        \n",
    "    # Case Folding\n",
    "    def CaseFolding(self, tweets):\n",
    "        tweets = tweets.lower()\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Cleansing\n",
    "    def Cleansing(self, tweets):\n",
    "        # Menghilangkan mention, hashtag, character reference\n",
    "        tweets = re.sub('[@#&][A-Za-z0-9_]+',\" \", tweets)\n",
    "\n",
    "        # Menghilangkan Tautan\n",
    "        tweets = re.sub(\"\\w+:\\/\\/\\S+\",\" \", tweets)\n",
    "\n",
    "        # Menghilangkan tanda baca\n",
    "        tweets = re.sub('[()!?;,]', ' ', tweets)\n",
    "        tweets = re.sub('\\[.*?\\]',' ', tweets)\n",
    "\n",
    "        # Menghilangkan tanda selain huruf\n",
    "        tweets = re.sub(\"[^a-z]\",\" \", tweets)\n",
    "\n",
    "        # Menghilangkan spasi lebih dari 1\n",
    "        tweets = ' '.join(tweets.split())\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Replace Slangwords\n",
    "    def Slangwords(self, tweets):\n",
    "        for line in self.slang_list:\n",
    "            slangword = line.strip().split(\":\")\n",
    "            if slangword[0] in tweets.split(\" \"):\n",
    "                tweets = tweets.replace(slangword[0] + \" \", slangword[1] + \" \")\n",
    "                tweets = tweets.replace(\" \" + slangword[0], \" \" + slangword[1])\n",
    "                \n",
    "        return tweets\n",
    "    \n",
    "    # Stopwords Removal\n",
    "    def StopwordsRemoval(self, tweets):\n",
    "        stopwords_list = list(map(lambda x:x.strip(),list(self.stopword_list)))\n",
    "        tweets = tweets.split()\n",
    "        tweets = [w for w in tweets if not w in stopwords_list]\n",
    "        tweets = \" \".join(word for word in tweets)\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Tokenization\n",
    "    def Tokenization(self, tweets):\n",
    "        tweets = tweets.split()\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Normalization (Stemming)\n",
    "    def Stemming(self, tweets):\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "        do = []\n",
    "        for w in tweets:\n",
    "            dt = stemmer.stem(w)\n",
    "            do.append(dt)\n",
    "        d_clean = []\n",
    "        d_clean = \" \".join(do)\n",
    "        print(d_clean)\n",
    "        \n",
    "        return d_clean\n",
    "    \n",
    "    def Stemming1(self, tweets):\n",
    "        stemmer = StemmerFactory.create_stemmer()\n",
    "        tweets = stemmer.stem(tweets)\n",
    "        print(tweets)\n",
    "\n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pretext = PreprocessingText()\n",
    "\n",
    "# ======================================================================================================================\n",
    "\n",
    "df_casefolding = df.copy()\n",
    "df_casefolding['tweet'] = df_casefolding['tweet'].apply(pretext.CaseFolding)\n",
    "\n",
    "df_cleansing = df_casefolding.copy()\n",
    "df_cleansing['tweet'] = df_cleansing['tweet'].apply(pretext.Cleansing)\n",
    "# df_cleansing = df_cleansing.drop_duplicates(subset='tweet')\n",
    "\n",
    "df_slangwords = df_cleansing.copy()\n",
    "df_slangwords['tweet'] = df_slangwords['tweet'].apply(pretext.Slangwords)\n",
    "\n",
    "df_stopwords = df_slangwords.copy()\n",
    "df_stopwords['tweet'] = df_stopwords['tweet'].apply(pretext.StopwordsRemoval)\n",
    "\n",
    "df_token = df_stopwords.copy()\n",
    "df_token['tweet'] = df_token['tweet'].apply(pretext.Tokenization)\n",
    "\n",
    "df_stemming = df_token.copy()\n",
    "# df_stemming['tweet'] = df_stemming['tweet'].apply(pretext.Stemming)\n",
    "\n",
    "dataAll = {'Raw Data': df, 'Case Folding': df_casefolding, 'Cleansing': df_cleansing, \n",
    "           'Normalization': df_slangwords, 'StopWords Removal': df_stopwords, 'Stemming': df_stemming,\n",
    "           'Tokenization': df_token}\n",
    "\n",
    "writer = pd.ExcelWriter('./kanjuruhan_sesudah_Preprocessed.xlsx', engine='xlsxwriter', mode='w')\n",
    "\n",
    "for data_sheet in dataAll.keys():\n",
    "    dataAll[data_sheet].to_excel(writer, sheet_name=data_sheet, index=False)\n",
    "\n",
    "writer.close()\n",
    "writer.handles = None\n",
    "\n",
    "print(\"\\n\\n\\nData Preprocessed Saved!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb865b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "# data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_positive = [t for t in data[\"label\"] if t == \"POSITIF\"]\n",
    "tweets_negative = [t for t in data[\"label\"] if t == \"NEGATIF\"]\n",
    "\n",
    "print(\"Hasil Sentimen Analisis\")\n",
    "print(\"POSITIF : \", len(tweets_positive), \"({}%)\".format(100*len(tweets_positive)/len(data)))\n",
    "print(\"NEGATIF : \", len(tweets_negative), \"({}%)\".format(100*len(tweets_negative)/len(data)))\n",
    "print(\"TOTAL : \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e568e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7b233f4b7a616658a1a466fdf5aa47a8e96adab13ae8534af036626bf05cb68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
