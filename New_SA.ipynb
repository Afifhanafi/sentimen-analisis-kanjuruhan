{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "07b7fd4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "class PreprocessingText:\n",
        "    def __init__(self):\n",
        "        self.slang_list = [kamus.strip('\\n').strip('\\r') for kamus in open('./daftar_slangwords.txt')]\n",
        "        self.stopword_list = [line.strip('\\n')for line in open('./daftar_stopwords.txt')]\n",
        "        \n",
        "    # Case Folding\n",
        "    def CaseFolding(self, tweets):\n",
        "        tweets = tweets.lower()\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Cleansing\n",
        "    def Cleansing(self, tweets):\n",
        "        # Menghilangkan mention, hashtag, character reference\n",
        "        tweets = re.sub('[@#&][A-Za-z0-9_]+',\" \", tweets)\n",
        "\n",
        "        # Menghilangkan Tautan\n",
        "        tweets = re.sub(\"\\w+:\\/\\/\\S+\",\" \", tweets)\n",
        "\n",
        "        # Menghilangkan tanda baca\n",
        "        tweets = re.sub('[()!?;,]', ' ', tweets)\n",
        "        tweets = re.sub('\\[.*?\\]',' ', tweets)\n",
        "\n",
        "        # Menghilangkan tanda selain huruf\n",
        "        tweets = re.sub(\"[^a-z]\",\" \", tweets)\n",
        "\n",
        "        # Menghilangkan spasi lebih dari 1\n",
        "        tweets = ' '.join(tweets.split())\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Replace Slangwords\n",
        "    def Slangwords(self, tweets):\n",
        "        for line in self.slang_list:\n",
        "            slangword, unslang = line.strip().split(\":\")\n",
        "            if slangword in tweets.split(\" \"):\n",
        "                tweets = tweets.replace(slangword + \" \", unslang + \" \")\n",
        "                tweets = tweets.replace(\" \" + slangword, \" \" + unslang)\n",
        "                \n",
        "        return tweets\n",
        "    \n",
        "    # Stopwords Removal\n",
        "    def StopwordsRemoval(self, tweets):\n",
        "        stopwords_list = list(map(lambda x:x.strip(),list(self.stopword_list)))\n",
        "        tweets = tweets.split()\n",
        "        tweets = [w for w in tweets if not w in stopwords_list]\n",
        "        tweets = \" \".join(word for word in tweets)\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Tokenization\n",
        "    def Tokenization(self, tweets):\n",
        "        tweets = tweets.split()\n",
        "        \n",
        "        return tweets\n",
        "    \n",
        "    # Normalization (Stemming)\n",
        "    def Stemming(self, tweets):\n",
        "        factory = StemmerFactory()\n",
        "        stemmer = factory.create_stemmer()\n",
        "        do = []\n",
        "        for w in tweets:\n",
        "            dt = stemmer.stem(w)\n",
        "            do.append(dt)\n",
        "        d_clean = []\n",
        "        d_clean = \" \".join(do)\n",
        "        print(d_clean)\n",
        "        \n",
        "        return d_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25ddce0b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:58:15 SE Asia Standard Time</td>\n",
              "      <td>1,43E+18</td>\n",
              "      <td>pinem3paska</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@Indostransfer Harapan saya  Agar Di Sumatera ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:54:57 SE Asia Standard Time</td>\n",
              "      <td>968410669</td>\n",
              "      <td>bhaniie_bsf</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@ocehangaluh Haha gimana mau degradasi orang d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:53:15 SE Asia Standard Time</td>\n",
              "      <td>116308596</td>\n",
              "      <td>awaveiro</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>Detail banget woy, sampe pager betis lompat aj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:48:16 SE Asia Standard Time</td>\n",
              "      <td>1,45E+18</td>\n",
              "      <td>loyalisgaruda</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>1,56E+18</td>\n",
              "      <td>2022-08-31 06:44:19 SE Asia Standard Time</td>\n",
              "      <td>1,27E+18</td>\n",
              "      <td>omah_balbalan</td>\n",
              "      <td>Positif</td>\n",
              "      <td>Kenapa sore?   PSSI dan LIB harus tahu ini.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
              "      <td>1,12E+18</td>\n",
              "      <td>fachsetiawan</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@lisadepe Ga salah dong gw ngidolain Ajax keti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:38 SE Asia Standard Time</td>\n",
              "      <td>7,08E+17</td>\n",
              "      <td>dulqowi</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@fedriza @PSSI Idem bro, sementara ini dulu aj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 06:02:04 SE Asia Standard Time</td>\n",
              "      <td>1,28E+18</td>\n",
              "      <td>ganesha010180</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@SiaranBolaLive Ga habis pikir, PSSI menggunak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 05:59:26 SE Asia Standard Time</td>\n",
              "      <td>1,33E+18</td>\n",
              "      <td>indones30065690</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@tirta_cipeng @PSSI Perusak Sepakbola Sejati I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>1,48E+18</td>\n",
              "      <td>2022-01-01 05:59:02 SE Asia Standard Time</td>\n",
              "      <td>1,28E+18</td>\n",
              "      <td>ganesha010180</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@SiaranBolaLive Problematik. Banyaknya sumber ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id conversation_id                                 created_at  \\\n",
              "0    1,56E+18        1,56E+18  2022-08-31 06:58:15 SE Asia Standard Time   \n",
              "1    1,56E+18        1,56E+18  2022-08-31 06:54:57 SE Asia Standard Time   \n",
              "2    1,56E+18        1,56E+18  2022-08-31 06:53:15 SE Asia Standard Time   \n",
              "3    1,56E+18        1,56E+18  2022-08-31 06:48:16 SE Asia Standard Time   \n",
              "4    1,56E+18        1,56E+18  2022-08-31 06:44:19 SE Asia Standard Time   \n",
              "..        ...             ...                                        ...   \n",
              "447  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
              "448  1,48E+18        1,48E+18  2022-01-01 06:02:38 SE Asia Standard Time   \n",
              "449  1,48E+18        1,48E+18  2022-01-01 06:02:04 SE Asia Standard Time   \n",
              "450  1,48E+18        1,48E+18  2022-01-01 05:59:26 SE Asia Standard Time   \n",
              "451  1,48E+18        1,48E+18  2022-01-01 05:59:02 SE Asia Standard Time   \n",
              "\n",
              "       user_id         username    label  \\\n",
              "0     1,43E+18      pinem3paska  Negatif   \n",
              "1    968410669      bhaniie_bsf  Negatif   \n",
              "2    116308596         awaveiro  Negatif   \n",
              "3     1,45E+18    loyalisgaruda  Negatif   \n",
              "4     1,27E+18    omah_balbalan  Positif   \n",
              "..         ...              ...      ...   \n",
              "447   1,12E+18     fachsetiawan  Positif   \n",
              "448   7,08E+17          dulqowi  Positif   \n",
              "449   1,28E+18    ganesha010180  Negatif   \n",
              "450   1,33E+18  indones30065690  Negatif   \n",
              "451   1,28E+18    ganesha010180  Negatif   \n",
              "\n",
              "                                                 tweet  \n",
              "0    @Indostransfer Harapan saya  Agar Di Sumatera ...  \n",
              "1    @ocehangaluh Haha gimana mau degradasi orang d...  \n",
              "2    Detail banget woy, sampe pager betis lompat aj...  \n",
              "3    @abdulra55101674 @sahaaat_ @Vand0e @OrenDepok ...  \n",
              "4          Kenapa sore?   PSSI dan LIB harus tahu ini.  \n",
              "..                                                 ...  \n",
              "447  @lisadepe Ga salah dong gw ngidolain Ajax keti...  \n",
              "448  @fedriza @PSSI Idem bro, sementara ini dulu aj...  \n",
              "449  @SiaranBolaLive Ga habis pikir, PSSI menggunak...  \n",
              "450  @tirta_cipeng @PSSI Perusak Sepakbola Sejati I...  \n",
              "451  @SiaranBolaLive Problematik. Banyaknya sumber ...  \n",
              "\n",
              "[452 rows x 7 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"Final_Sebelum_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5cdc9047",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "harap sumatera utara kalimantan iri jaya tayang tanding jawa\n",
            "mundur orang selamat pssi\n",
            "detail pager betis lompat pikir\n",
            "risiko hadap malam rawan celaka teman teman saudara korban tanding terlakamu malam marah marah jadwal malam\n",
            "sore pssi lib\n",
            "ketua pssi mochamad iriawan stadion piala dunia u tetap enam stadion kurang\n",
            "jam tayang malam ubah evaluasi tutup mulut admin jatuh korban\n",
            "temu sponsor pssi pasti piala indonesia gelar\n",
            "hormat beku psim jogja konsekuensi dukung nyawa hilang sepak bola harga nyawa manusia adil damai\n",
            "api asap bom takut psm makassar denda komdis pssi\n",
            "periksa fifa pssi stadion piala dunia u kurang\n",
            "jalas pikir benang pendek\n",
            "jakarta panitia pikir lambat main malam\n",
            "pssi stadion piala dunia u kurang\n",
            "promosi kasta tinggi litidak kait siap baik ayo kelas profesional kait beli tiket terus\n",
            "atur saing tim menang p ketua mesti strategi syarat juara aff kalah vietnam thailand anggap peringkat vietnam kerja keras\n",
            "tanggap pssi aff nyata vietnam thailand langgar main adil piala aff u\n",
            "jalan emang pssi fasilitas hambat gaji\n",
            "langkah aff sesuai prosedur sayaukur pssi hormat putus aff main\n",
            "saing pssi liga seri latih satria nurzaman buka daftar main persik diri daftar ikut proses\n",
            "kasih data asli alas\n",
            "dasar balik fakta\n",
            "aff temu curang duel vietnam lawan thailand piala aff u respon pssi\n",
            "pssi departemen dukung\n",
            "foto ketua pssi berita korupsi keren\n",
            "anjing bicara dilakban sipit korupsi\n",
            "uang organisasi urus lantang suara kerja sekian cinta sepak bola dukung hadir stadion semangat garuda muda\n",
            "diam korupsi uang rakyat\n",
            "positif pikir bantu kapal korea\n",
            "memang orang lahir papua takut orang seperti sentuh babi jadi sentuh manusia\n",
            "maju sepak bola indoneia dewasa oknum dukung indonesia dukung jaga liga indonesia masyarakat indonesia oknum berfikir egois\n",
            "kpk kpi bumn mui kominfo dpr pssi lawak menteri\n",
            "negeri serta cipta\n",
            "lepas minim bagan desak langsung sepak bola gomez hasil tonton main paksa tarung semangat pulang kali gomez suara aspirasi yangansa emosional bobotoh kritik kelola pssi obet\n",
            "wasit progres naik signifikan\n",
            "bahas esemka proyek susilo bambang yudhoyono paham\n",
            "u tiket murah tiket habis keluar tonton luber pssi suka habis uang\n",
            "dukung opm sebar luas dukung teroris tuju putus debat campur urus perintah\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [5], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m df_token[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_token[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(pretext\u001b[39m.\u001b[39mTokenization)\n\u001b[0;32m     18\u001b[0m df_stemming \u001b[39m=\u001b[39m df_token\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 19\u001b[0m df_stemming[\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_stemming[\u001b[39m'\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(pretext\u001b[39m.\u001b[39;49mStemming)\n\u001b[0;32m     21\u001b[0m dataAll \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mRaw Data\u001b[39m\u001b[39m'\u001b[39m: df, \u001b[39m'\u001b[39m\u001b[39mCase Folding\u001b[39m\u001b[39m'\u001b[39m: df_casefolding, \u001b[39m'\u001b[39m\u001b[39mCleansing\u001b[39m\u001b[39m'\u001b[39m: df_cleansing, \n\u001b[0;32m     22\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mSlangwords\u001b[39m\u001b[39m'\u001b[39m: df_slangwords, \u001b[39m'\u001b[39m\u001b[39mStopWords\u001b[39m\u001b[39m'\u001b[39m: df_stopwords, \u001b[39m'\u001b[39m\u001b[39mTokenizing\u001b[39m\u001b[39m'\u001b[39m: df_token,\n\u001b[0;32m     23\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mStemming\u001b[39m\u001b[39m'\u001b[39m: df_stemming}\n\u001b[0;32m     25\u001b[0m writer \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mExcelWriter(\u001b[39m'\u001b[39m\u001b[39m./Data_Sebelum_Preprocessed.xlsx\u001b[39m\u001b[39m'\u001b[39m, engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mxlsxwriter\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn [1], line 67\u001b[0m, in \u001b[0;36mPreprocessingText.Stemming\u001b[1;34m(self, tweets)\u001b[0m\n\u001b[0;32m     65\u001b[0m do \u001b[39m=\u001b[39m []\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tweets:\n\u001b[1;32m---> 67\u001b[0m     dt \u001b[39m=\u001b[39m stemmer\u001b[39m.\u001b[39;49mstem(w)\n\u001b[0;32m     68\u001b[0m     do\u001b[39m.\u001b[39mappend(dt)\n\u001b[0;32m     69\u001b[0m d_clean \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py:20\u001b[0m, in \u001b[0;36mCachedStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m     stems\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\u001b[39m.\u001b[39mget(word))\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelegatedStemmer\u001b[39m.\u001b[39;49mstem(word)\n\u001b[0;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\u001b[39m.\u001b[39mset(word, stem)\n\u001b[0;32m     22\u001b[0m     stems\u001b[39m.\u001b[39mappend(stem)\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:27\u001b[0m, in \u001b[0;36mStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     24\u001b[0m stems \u001b[39m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words:\n\u001b[1;32m---> 27\u001b[0m     stems\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstem_word(word))\n\u001b[0;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(stems)\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:36\u001b[0m, in \u001b[0;36mStemmer.stem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstem_plural_word(word)\n\u001b[0;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstem_singular_word(word)\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:84\u001b[0m, in \u001b[0;36mStemmer.stem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m context \u001b[39m=\u001b[39m Context(word, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisitor_provider)\n\u001b[1;32m---> 84\u001b[0m context\u001b[39m.\u001b[39;49mexecute()\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m context\u001b[39m.\u001b[39mresult\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:37\u001b[0m, in \u001b[0;36mContext.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m\"\"\"Execute stemming process; the result can be retrieved with result\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m#step 1 - 5\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_stemming_process()\n\u001b[0;32m     39\u001b[0m \u001b[39m#step 6\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary\u001b[39m.\u001b[39mcontains(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word):\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:80\u001b[0m, in \u001b[0;36mContext.start_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m#step 4, 5\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremove_prefixes()\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary\u001b[39m.\u001b[39mcontains(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word):\n\u001b[0;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:89\u001b[0m, in \u001b[0;36mContext.remove_prefixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_prefixes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m---> 89\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccept_prefix_visitors(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprefix_pisitors)\n\u001b[0;32m     90\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary\u001b[39m.\u001b[39mcontains(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word):\n\u001b[0;32m     91\u001b[0m             \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32mf:\\Kuliah\\TA\\sentimen-analisis-kanjuruhan\\venv\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:113\u001b[0m, in \u001b[0;36mContext.accept_prefix_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary\u001b[39m.\u001b[39mcontains(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word):\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word\n\u001b[1;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_is_stopped:\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_word\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremovals) \u001b[39m>\u001b[39m removalCount:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pretext = PreprocessingText()\n",
        "\n",
        "df_casefolding = df.copy()\n",
        "df_casefolding['tweet'] = df_casefolding['tweet'].apply(pretext.CaseFolding)\n",
        "\n",
        "df_cleansing = df_casefolding.copy()\n",
        "df_cleansing['tweet'] = df_cleansing['tweet'].apply(pretext.Cleansing)\n",
        "\n",
        "df_slangwords = df_cleansing.copy()\n",
        "df_slangwords['tweet'] = df_slangwords['tweet'].apply(pretext.Slangwords)\n",
        "\n",
        "df_stopwords = df_slangwords.copy()\n",
        "df_stopwords['tweet'] = df_stopwords['tweet'].apply(pretext.StopwordsRemoval)\n",
        "\n",
        "df_token = df_stopwords.copy()\n",
        "df_token['tweet'] = df_token['tweet'].apply(pretext.Tokenization)\n",
        "\n",
        "df_stemming = df_token.copy()\n",
        "df_stemming['tweet'] = df_stemming['tweet'].apply(pretext.Stemming)\n",
        "\n",
        "dataAll = {'Raw Data': df, 'Case Folding': df_casefolding, 'Cleansing': df_cleansing, \n",
        "       'Slangwords': df_slangwords, 'StopWords': df_stopwords, 'Tokenizing': df_token,\n",
        "       'Stemming': df_stemming}\n",
        "\n",
        "writer = pd.ExcelWriter('./Data_Sebelum_Preprocessed.xlsx', engine='xlsxwriter', mode='w')\n",
        "\n",
        "for data_sheet in dataAll.keys():\n",
        "    dataAll[data_sheet].to_excel(writer, sheet_name=data_sheet, index=False)\n",
        "\n",
        "writer.close()\n",
        "\n",
        "print(\"\\n\\n\\nData Preprocessed Saved!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6bb865b5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-16 05:18:19 SE Asia Standard Time</td>\n",
              "      <td>1,49E+18</td>\n",
              "      <td>alhusaini_asror</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@mohmahfudmd Benar dan Betul.Ketua PSSI,mundur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-16 05:13:51 SE Asia Standard Time</td>\n",
              "      <td>1442933096</td>\n",
              "      <td>metmalamminggu</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@iIhamzada Dilarang intervensi gara\" aturan fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-16 05:06:34 SE Asia Standard Time</td>\n",
              "      <td>7,88E+17</td>\n",
              "      <td>onedayasmine</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@gibran_tweet Mas.. jadi ketua PSSI yaaa Kalau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-16 05:03:44 SE Asia Standard Time</td>\n",
              "      <td>4812772283</td>\n",
              "      <td>harryunited05</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@medioclubID @PSSI mana orangnya itu2 aja lagi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-16 05:00:24 SE Asia Standard Time</td>\n",
              "      <td>1,31E+18</td>\n",
              "      <td>ariflabmed</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@medioclubID @PSSI Yunus Nusi akan dikenang se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-07 11:47:59 SE Asia Standard Time</td>\n",
              "      <td>521254614</td>\n",
              "      <td>bodoamath</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>lho kapolda sama ketua pssi nya mana?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-07 11:47:24 SE Asia Standard Time</td>\n",
              "      <td>1,57E+18</td>\n",
              "      <td>crypto34209511</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@PSSI HAK DAN KEWAJIBAN PENONTON HARUS DI INGA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-07 11:43:10 SE Asia Standard Time</td>\n",
              "      <td>2156012929</td>\n",
              "      <td>gbrand_9127</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@CNNIndonesia PSSI juga gk standar FIFA.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-07 11:41:33 SE Asia Standard Time</td>\n",
              "      <td>480858414</td>\n",
              "      <td>grrraargh</td>\n",
              "      <td>Negatif</td>\n",
              "      <td>@ainurohman Dia pikir PSSI cuma urus timnas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>1,58E+18</td>\n",
              "      <td>2022-10-07 11:40:32 SE Asia Standard Time</td>\n",
              "      <td>1056988237</td>\n",
              "      <td>davasca_</td>\n",
              "      <td>Positif</td>\n",
              "      <td>@Gust_Neg @Gusnaabi1 @gumpnhell ((Enak aje mun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1238 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id conversation_id                                 created_at  \\\n",
              "0     1,58E+18        1,58E+18  2022-10-16 05:18:19 SE Asia Standard Time   \n",
              "1     1,58E+18        1,58E+18  2022-10-16 05:13:51 SE Asia Standard Time   \n",
              "2     1,58E+18        1,58E+18  2022-10-16 05:06:34 SE Asia Standard Time   \n",
              "3     1,58E+18        1,58E+18  2022-10-16 05:03:44 SE Asia Standard Time   \n",
              "4     1,58E+18        1,58E+18  2022-10-16 05:00:24 SE Asia Standard Time   \n",
              "...        ...             ...                                        ...   \n",
              "1233  1,58E+18        1,58E+18  2022-10-07 11:47:59 SE Asia Standard Time   \n",
              "1234  1,58E+18        1,58E+18  2022-10-07 11:47:24 SE Asia Standard Time   \n",
              "1235  1,58E+18        1,58E+18  2022-10-07 11:43:10 SE Asia Standard Time   \n",
              "1236  1,58E+18        1,58E+18  2022-10-07 11:41:33 SE Asia Standard Time   \n",
              "1237  1,58E+18        1,58E+18  2022-10-07 11:40:32 SE Asia Standard Time   \n",
              "\n",
              "         user_id         username    label  \\\n",
              "0       1,49E+18  alhusaini_asror  Negatif   \n",
              "1     1442933096   metmalamminggu  Negatif   \n",
              "2       7,88E+17     onedayasmine  Negatif   \n",
              "3     4812772283    harryunited05  Negatif   \n",
              "4       1,31E+18       ariflabmed  Positif   \n",
              "...          ...              ...      ...   \n",
              "1233   521254614        bodoamath  Negatif   \n",
              "1234    1,57E+18   crypto34209511  Negatif   \n",
              "1235  2156012929      gbrand_9127  Negatif   \n",
              "1236   480858414        grrraargh  Negatif   \n",
              "1237  1056988237         davasca_  Positif   \n",
              "\n",
              "                                                  tweet  \n",
              "0     @mohmahfudmd Benar dan Betul.Ketua PSSI,mundur...  \n",
              "1     @iIhamzada Dilarang intervensi gara\" aturan fi...  \n",
              "2     @gibran_tweet Mas.. jadi ketua PSSI yaaa Kalau...  \n",
              "3     @medioclubID @PSSI mana orangnya itu2 aja lagi...  \n",
              "4     @medioclubID @PSSI Yunus Nusi akan dikenang se...  \n",
              "...                                                 ...  \n",
              "1233              lho kapolda sama ketua pssi nya mana?  \n",
              "1234  @PSSI HAK DAN KEWAJIBAN PENONTON HARUS DI INGA...  \n",
              "1235           @CNNIndonesia PSSI juga gk standar FIFA.  \n",
              "1236        @ainurohman Dia pikir PSSI cuma urus timnas  \n",
              "1237  @Gust_Neg @Gusnaabi1 @gumpnhell ((Enak aje mun...  \n",
              "\n",
              "[1238 rows x 7 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "# data = pd.read_csv(\"Final_Sesudah_Kanjuruhan.csv\", sep=';', encoding='unicode_escape')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92af24e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil Sentimen Analisis\n",
            "Positif :  619 (50.0%)\n",
            "Negatif :  619 (50.0%)\n",
            "TOTAL :  1238\n"
          ]
        }
      ],
      "source": [
        "tweets_positive = [t for t in data[\"label\"] if t == \"Positif\"]\n",
        "tweets_negative = [t for t in data[\"label\"] if t == \"Negatif\"]\n",
        "\n",
        "print(\"Hasil Sentimen Analisis\")\n",
        "print(\"Positif : \", len(tweets_positive), \"({}%)\".format(100*len(tweets_positive)/len(data)))\n",
        "print(\"Negatif : \", len(tweets_negative), \"({}%)\".format(100*len(tweets_negative)/len(data)))\n",
        "print(\"TOTAL : \", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b992bfee",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a7b233f4b7a616658a1a466fdf5aa47a8e96adab13ae8534af036626bf05cb68"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
